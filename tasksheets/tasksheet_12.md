# Solutions for Tasksheet 12
[See here](https://github.com/jvkoebbe/math4610/blob/master/tasksheets/tasksheet_12/html/tasksheet_12.html) for problem set.

<hr>

**Task 1**

<hr>

**Task 2**

<hr>

**Task 3**

<hr>

**Task 4**

<hr>

**Task 5**

<hr>

**Task 6**

OpenMP is not the only library available for parallel processing. Other options for parallelization include Message Passing Interface (MPI) and CUDA. MPI is a standard developed for communication in parallel computing architectures ([https://en.wikipedia.org/wiki/Message_Passing_Interface)](https://en.wikipedia.org/wiki/Message_Passing_Interface)). MPI was designed for scalability, portability and performance. CUDA is much more platform specific parallel computing toolkit. CUDA is owned and maintained by Nvidia, who specializes in high-performance GPUs ([https://developer.nvidia.com/cuda-toolkit](https://developer.nvidia.com/cuda-toolkit)). CUDA only works on Nvidia-supported Graphics Processing Units (GPU).
